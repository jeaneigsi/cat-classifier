{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeaneigsi/cat-classifier/blob/main/cat_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "la_Oz6oLlub6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb341b51-e5ca-46f4-c2e3-4d34c73908fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, BatchNormalization, MaxPooling2D,Input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "jaF8r6aOl48C"
      },
      "outputs": [],
      "source": [
        "# Get project files\n",
        "# !wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "# !unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = '/content/cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "EOJFeEfumns6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86b0843-3cf5-43ef-a75e-66b040255b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 50 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# 3\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "validation_image_generator= ImageDataGenerator(rescale=1./255,)\n",
        "test_image_generator=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen =train_image_generator.flow_from_directory(\n",
        "    '/content/cats_and_dogs/train',\n",
        "     target_size=(224, 224),\n",
        "     batch_size=128,\n",
        "     class_mode='binary',\n",
        "\n",
        ")\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "     '/content/cats_and_dogs/validation',\n",
        "     target_size=(224, 224),\n",
        "     batch_size=128,\n",
        "     class_mode='binary'\n",
        "\n",
        ")\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "    '/content/cats_and_dogs/test',\n",
        "     target_size=(224, 224),\n",
        "     batch_size=128,\n",
        "     shuffle=True,\n",
        "    classes=[\".\"], #permet de considerer le path comme repertoire principale en l'abscence de sous repertoire\n",
        "     class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0WA8j1mt7Q"
      },
      "outputs": [],
      "source": [
        "# 4\n",
        "def plotImages(images_arr, probabilities = False):\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
        "    if probabilities is False:\n",
        "      for img, ax in zip( images_arr, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "    else:\n",
        "      for img, probability, ax in zip( images_arr, probabilities, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "          if probability > 0.5:\n",
        "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
        "          else:\n",
        "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
        "    plt.show()\n",
        "\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "-32RRLY_3voj"
      },
      "outputs": [],
      "source": [
        "# 5\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    zoom_range=0.1,\n",
        "    vertical_flip=False,\n",
        "    horizontal_flip = True,\n",
        "    rescale=1./255.,\n",
        "    width_shift_range =0.1,\n",
        "    height_shift_range =0.1,\n",
        "    shear_range=0.1,\n",
        "    brightness_range = [0.8, 1],\n",
        "    fill_mode=\"nearest\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkwq2LFvqabS"
      },
      "outputs": [],
      "source": [
        "# 6\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "print(type(train_data_gen))\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "k8aZkwMam4UY"
      },
      "outputs": [],
      "source": [
        "# 7 Definition du modèle avec 58% de précision\n",
        "\n",
        "# model = Sequential(\n",
        "#    [ tf.keras.layers.Conv2D(16, 3, activation = 'relu', input_shape = (150, 150, 3)),\n",
        "#     tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Dropout(0.2),\n",
        "#     tf.keras.layers.Conv2D(32, 3, activation = 'relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Dropout(0.2),\n",
        "#     tf.keras.layers.Conv2D(64, 3, activation = 'relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Dropout(0.2),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "#     tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "#     tf.keras.layers.Dense(2, activation = 'softmax')]\n",
        "\n",
        "# )\n",
        "\n",
        "# model.compile( optimizer = 'adam',\n",
        "#               loss = 'sparse_categorical_crossentropy',\n",
        "#               metrics = ['accuracy']\n",
        "# )\n",
        "\n",
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8H9geU3xI7B"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geler les poids du modèle pré-entraîné par transfert learning 63%\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# # Créer le modèle séquentiel pour l'ajustement\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2,activation='sigmoid')  # Utilisation de 'sigmoid' car il s'agit d'un problème de classification binaire\n",
        "])\n",
        "\n",
        "# # Compiler le modèle\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Afficher un résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cT9g_CaMSVPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977a3883-d237-4e57-b927-f7df5eb0fb06"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 1280)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               327936    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2586434 (9.87 MB)\n",
            "Trainable params: 328450 (1.25 MB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "\n",
        "steps_per_epoch=ceil(len(train_data_gen)/batch_size)\n",
        "steps_per_epoch"
      ],
      "metadata": {
        "id": "RMXboz6KrHP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_steps = ceil(len(val_data_gen) / batch_size)\n",
        "validation_steps"
      ],
      "metadata": {
        "id": "cArB_C3vr-qH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8a1341-0678-49dd-9d16-be896b37aeb2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niQDz5x6K7y"
      },
      "outputs": [],
      "source": [
        "# 8\n",
        "history = model.fit(\n",
        "    train_data_gen, #generateur\n",
        "    epochs=epochs,# episode\n",
        "    validation_data=val_data_gen, # données de consideration\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('cat_detector_58.h5')"
      ],
      "metadata": {
        "id": "YrYW2aALxahm"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('cat_detctor_59.keras')"
      ],
      "metadata": {
        "id": "UmcuJ_VrxtRW"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xS51mB56OAC"
      },
      "outputs": [],
      "source": [
        "# 9\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYrSifOit2aK"
      },
      "outputs": [],
      "source": [
        "predictions=model.predict(test_data_gen,verbose=1)\n",
        "print(predictions)\n",
        "probabilities = []\n",
        "for a in predictions:\n",
        "  if a[0] > a[1]:\n",
        "    probabilities.append(0)\n",
        "  else:\n",
        "    probabilities.append(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvd2VPijZXTW"
      },
      "outputs": [],
      "source": [
        "print(len(probabilities))\n",
        "print(type(probabilities))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_training_images, _ = next(test_data_gen)\n",
        "print(probabilities)\n",
        "plotImages(sample_training_images[:15], probabilities)\n",
        "#0=chat et 1=chien"
      ],
      "metadata": {
        "id": "ucXpCT463a1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "4IH86Ux_u7TZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d254c2-4d00-4671-9b38-87f133067d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "Your model correctly identified 64.0% of the images of cats and dogs.\n",
            "You passed the challenge!\n"
          ]
        }
      ],
      "source": [
        "# 11\n",
        "answers =  [1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
        "            1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
        "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
        "            0, 0, 0, 1, 0, 0]\n",
        "print(len(answers))\n",
        "correct = 0\n",
        "\n",
        "for probability, answer in zip(probabilities, answers):\n",
        "  if round(probability) == answer:\n",
        "    correct +=1\n",
        "\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "passed_challenge = percentage_identified >= 63\n",
        "\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "  print(\"You passed the challenge!\")\n",
        "else:\n",
        "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}